- [ ] 详细说明推理轨迹（CoT）输出的结构与示例，补充生成与使用细节（§3.2）。
  - 增加标准化 CoT 输出模板：包含步骤编号、引用的 ES 操作（op id / span id）、“决策理由 → 代码变更”映射，以及最终合并结果的指向关系。
  - 选取 2–3 个具代表性的例子（来自 `output/cot/0623_1803_with_guide/correct` 与 `error`），在正文或附录中展示完整 CoT 片段（含 `<cot>...</cot>` 标签）与对应输入/输出。
  - 说明模型训练/推理时 CoT 的使用方式：是否强制输出 CoT、是否在评测时剥离 CoT 仅比对代码、CoT 是否参与损失函数（例如联合学习）。
  - 明确 CoT 与 ES 的对齐方式：CoT 步骤应可回溯到具体 ES 片段与源分支（A/B/O），并在论文中给出对齐规则与示例。
  - 在补充材料中提供若干 CoT 样例文件列表与路径，便于审稿人核对与复现（指向 `output/cot/.../correct/*.txt`）。

- [ ] 扩展消融实验：分别在单语与跨语言设置，独立评估 ES 与 CoT 的贡献；加入“仅移除 CoT”等可比变体。
  - 在 RQ3（单语）与 RQ4（跨语）形成对称的消融矩阵：w/o ES、w/o CoT、w/o ES&CoT、Full（ES+CoT），并保持相同数据与评测流程。
  - 报告每种变体在 Precision/Accuracy 上的均值±标准差（多随机种子），并进行显著性检验（例如 bootstrap 或 t-test）。
  - 针对“ES 贡献仅 1.7/1.9pp”的质疑，补充更多维度（AST 结构一致率、语法有效率、失败类型占比）以佐证 ES 的细粒度收益。

- [ ] 补充各语言两阶段（Stage 1/2）结果，并阐明 Stage 2 正确性校验方法与标准。
  - Stage 1：教师模型生成候选 CoT+合并结果；记录每语言生成条数、平均 token、失败率（如空响应/超长截断）。
  - Stage 2：正确性判定标准应明确且可复现（首选“最终代码与金标准 exact match”；可附加“语法通过 + 语义近似”作为次级过滤）。
  - 给出各语言 Stage 1→Stage 2 的通过率（已有部分在 fix.md，可并入主表），并公开核验脚本接口（解析/比对规则、忽略空白/格式选项）。
  - 说明错误样本如何处理（剔除/重采样/弱标注使用），避免数据泄漏与标签噪声。
- [ ] 重新评估数据划分：当前测试集仅 10%，尝试并报告 80/20、70/30 等划分对结果与稳定性的影响。
  - 与 MergeBERT/ChatMerge 完全对齐的数据折分（若其公开），若不一致则在相同折分上复现实验并单列报告；
  - 多随机种子重复（≥3），报告均值±标准差；
  - 发布使用的随机种子与划分清单，确保可复现。
- [ ] 更谨慎地解读 RQ4 结论：讨论基础模型已见过目标语言的影响；与“直接生成”做更公平对比（改进设置与分析）。
  - 明确基础模型的预训练语料覆盖（JS/TS 等），区分“真正跨语言迁移”与“已见语言的迁移”。
  - 增加更公平的 Direct Generation 对比：统一输入格式、上下文窗口、长度约束，并控制调用次数与温度等超参；
  - 报告跨语言设置下的 ablation（w/o ES、w/o CoT），并讨论各组件在“已见/未见语言”下的边际贡献差异。
- [ ] 量化第 6.1 节计算开销（训练/推理成本、时延、调用次数等），给出可复现实验数字。
  - 训练：记录教师模型生成成本（调用次数、平均/总 token、总费用或 GPU 时长）、SFT 微调开销（epoch、batch、硬件、时长）。
  - 推理：单样本平均时延、平均 token、并发设置、稳定性（超时/失败率）。
  - 以统一单位呈现成本（如 USD/万样本、GPU-hour/epoch）并提供估算脚本或表格。
- [ ] 在每个 RQ 末增加“关键结论/启示”小结，强化可复用经验。
  - 采用固定模板：结论要点（1–3 条）、对实践的启示、对未来研究的建议/限制。
- [  ] 在表 1–4 增加与各基线的差值（±x%）列，便于横向比较。
  - 已在 `fix.md` 草拟 Δ 列，合并至论文主表，并标注“pp（百分点）”。
- [ ] 在 RQ1 中验证“将任务表述为推理”的动机：用具体样例对比分类/生成基线失败原因（如缺上下文），并量化占比。
  - 抽取 MergeCoT 优于 MergeBERT 的样本，标注失败原因类别（缺上下文/语义替换/变量别名/跨行依赖等）与占比；
  - 给出 2–3 个可读示例，展示“推理步骤如何弥补分类/直接生成的盲点”。
- [ ] 与“推理型模型（隐式 CoT）”对比：说明为何不直接使用/微调推理模型获取轨迹，并给出实验比较。
  - 选取公开可测的“Reasoning”模型（如 GPT-4.1/4o-mini-Reasoning、Qwen-Reasoner 等），在相同输入与预算下比较：
    1) 直接用隐式 CoT 生成；2) 明确提示要求 CoT；3) 我们的 ES+显式 CoT。
  - 对比指标：Exact match、语法通过率、成本、时延；附示例 CoT 片段的可解释性对比。
- [ ] 评估 CoT 轨迹有效性：增加 CoT 消融与对比（含与推理模型原生轨迹的比较），回答其对性能的真实贡献。
  - 设计“CoT 质量度量”：步骤-ES 对齐率、因果一致性（步骤结论与代码变更一致率）、自洽性（重复问答一致率）。
  - 统计 CoT 质量分桶对性能的影响（如高/中/低质 CoT 的 Accuracy）。
- [ ] 深化失败案例分析：给出各类失败的数量分布与比例，并配代表性案例。
  - 建立失败类型分类法：语法错误、变量对齐错误、逻辑遗漏、跨行/跨块依赖、误合并、上下文缺失等；
  - 至少给出每类 1–2 例，附简短“如何通过 ES/CoT 规避”的讨论。
- [ ] 澄清贡献边界：明确与既有工作关系（MergeBERT/ChatMerge 的 ES、ConGra 的 CoT、STaR 的数据构造），调整措辞避免过强表述。
  - 在“贡献”与“方法”处重写表述：强调“组合式新颖性 + 在合并冲突域的系统化落地”，避免将 ES/CoT/STaR 描述为首次提出。
  - 在相关工作中主动对比 ConGra、STaR 的异同与借鉴关系，并解释 CoT 在本任务中的定制化设计（ES 对齐、两阶段筛选等）。
- [ ] 解决命名歧义：重命名 §3.2 中的“K”，避免与“2K 次调用”的歧义。
  - 将“K”改为更具体的 `k_conflicts`、`k_candidates` 或 `k_calls`，并全篇统一。
- [ ] 与 MergeBERT、ChatMerge 使用相同数据划分；若不同需在相同划分上复现实验；考虑多随机划分验证稳定性。
  - 若其划分未公开或不可复现，明确说明并提供我们公开划分；同时报告“在相同我们划分上”的对比复现结果。
- [ ] 说明选择 diff3 与 JDIME 作为基线的理由；明确其“冲突解决”度量口径，并解释如何计算精度/准确率。
  - 定义对该类工具的评测方式：若输出含冲突标记，一律计为语法失败（Precision=0）；Accuracy 仅在金标准亦为冲突标记时可能>0；
  - 或者分列“冲突保留率/可解析率/Exact match”等指标，避免与 ML 方法混淆，正文明确口径差异。
- [ ] 解释“准确率高于精度”的现象；如使用了其数据子集，应在相同子集上重跑并报告。
  - 重复运行 MergeBERT/ChatMerge 于相同数据与口径，核对其 Precision/Accuracy 关系；若复现实验显示相反关系，需分析原因（评测脚本/语法判定/过滤规则）。
- [ ] 扩充数据集描述：按语言列出训练/验证/测试样本数与规模表。
  - 补充各语言样本数、平均/中位冲突块长度、冲突类型（A/B/A+B 等）分布；
  - 公开数据统计脚本与版本信息，保证一键复现。
- [ ] 回应“GPT-4 + 简单 CoT 提示即可”的质疑：提供更有力的对比/论证或实证实验。
  - 实验：同预算下的简单 CoT 提示（如“explain step by step”）vs 我们的 ES+CoT 提示/微调；
  - 论证：简单提示难覆盖变量对齐/跨块依赖等结构性信息，ES 显式提供结构先验并降低幻觉。
- [ ] 讨论/展示是否向开发者呈现 CoT 解释：给出定性示例并（若可）提供初步可用性评估。
  - 在附录或网页展示 3–5 个真实 CoT+合并结果示例图；
  - 设计小规模开发者可用性调查或案例访谈，收集“信任/理解/采纳”主观反馈。
- [ ] 明确度量定义与一致性：重申 precision 定义并讨论“何为冲突”的一致性设定对评测的影响。
  - 在评测节固定术语：Exact match、Parse success、Precision（可解析且冲突解决正确的比例）等，并给出正式公式；
  - 明确“冲突”的统一定义与解析方式（textual vs structured），并解释其对各工具的影响。
- [ ] 评估并考虑合并/重构 RQ2（与 RQ1 的关系与冗余）。
  - 若保留 RQ2，需突出与 RQ1 的边界与互补；若合并，给出新的结构与过渡说明。
- [ X ] 修正文稿小问题（按行号）： //已经改好
  - l.204–205, 248 增补/规范引用；
  - l.212 术语“tentative merge result”澄清；
  - l.213 行尾“||||||||”处理；
  - l.302 解释“highly generalised”；
  - l.315–316 统一 A->1, B->2 标注；
  - l.351 单词“Conflict”检查；
  - l.353, 358 删去示例首行非冲突内容；
  - l.505 定义符号“X”；
  - l.567（及 l.576）定义 r_i；
  - l.621 去掉“about”并补充其他语言的 CoT 情况；
  - l.660 调整“human”措辞（可能为工具选择 OURS）；
  - l.944 删除“large”。
- [ ] 回答审稿问题（用于 rebuttal/修订说明）：
  - 是否与 MergeBERT/ChatMerge 使用完全相同的数据集及折分？
  - 为何选择 diff3/JDIME 以及如何解释其精度/准确率＞0？
  - 模型输入是否仅为冲突块，无更宽上下文？如是，给出理由与影响分析；
  - 在 ES 中如何区分多个出现的同一 token X（实例区分方案）。

- [ ] DSL / ES 设计细节与替换方案（回应“MOVE/采用 SOTA ES 工具”的建议）。
  - 说明当前 ES 能力边界（token 级 ADD/DEL/REPL，不含 MOVE），并解释任务需求与权衡；
  - 给出“以 GumTree（或等价工具）替换 ES 生成器”的实验计划与可行性评估（token 适配、成本、对齐规则变化）。
  - 设计 X 的多次出现的消歧：为 ES 片段增加 `span id`/位置索引（如 [start,end) 或 occurrence id），并在 CoT 中引用该 id。

- [ ] 输入上下文范围实验与澄清（回应“仅冲突块输入”的疑问）。
  - 系统实验四档：仅冲突块、±N 行上下文、文件级上下文、跨文件/项目上下文（若可）；
  - 对比各档的收益/成本变化，并解释我们在主实验选择的默认档位与原因（效率/可复现/模型限制）。

- [ ] 结果可视化与附录材料完善。
  - 为 RQ1–RQ4 各补 1 幅“代表性输入→ES→CoT→输出”的流程图或文本框对齐图；
  - 将 `fix.md` 中 Δ 表合并并在表注中说明计算口径与显著性标注；
  - 在附录提供：数据统计表、评测脚本接口、样例清单（文件路径）。

- [ ] 威胁与可重复性（Threats to Validity）补充。
  - 划分随机性、基础模型预训练语料偏置、评测口径（textual vs structured）差异等；
  - 发布代码/数据与运行参数（含随机种子）、环境说明，保证完全复现。
